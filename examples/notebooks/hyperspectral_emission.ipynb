{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# if os.path.exists(\"/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\"):\n",
    "#     os.environ[\"TENSORSTORE_CA_BUNDLE\"] = \"/etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsim import schema as ms\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple Filter through a function that allows us to set min and max values for the spectrum\n",
    "def create_custom_channel(\n",
    "    min_wave: int = 300, \n",
    "    max_wave: int = 800,\n",
    ") -> ms.optical_config.OpticalConfig:\n",
    "\n",
    "    custom_spectrum = ms.Spectrum(\n",
    "        wavelength=np.arange(min_wave, max_wave, 1),\n",
    "        intensity=np.ones(max_wave - min_wave),\n",
    "    )\n",
    "\n",
    "    custom_filter = ms.optical_config.SpectrumFilter(transmission=custom_spectrum) # placement=ALL by default\n",
    "\n",
    "    custom_channel = ms.optical_config.OpticalConfig(\n",
    "        name=\"FEDERICO\",\n",
    "        filters=[custom_filter],\n",
    "    )\n",
    "    \n",
    "    return custom_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ch = create_custom_channel()\n",
    "\n",
    "print(my_ch.filters[0].spectrum)\n",
    "print(my_ch.filters[0].spectrum.wavelength.shape, type(my_ch.filters[0].spectrum.wavelength))\n",
    "print(my_ch.filters[0].spectrum.intensity.shape, type(my_ch.filters[0].spectrum.intensity), max(my_ch.filters[0].spectrum.intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microsim.schema.optical_config import lib\n",
    "\n",
    "sim = ms.Simulation(\n",
    "    truth_space=ms.ShapeScaleSpace(shape=(52, 512, 512), scale=(0.064, 0.064, 0.064)),\n",
    "    output_space={\"downscale\": 2},\n",
    "    sample=ms.Sample(\n",
    "        labels=[\n",
    "            ms.FluorophoreDistribution(\n",
    "                distribution=ms.CosemLabel(dataset=\"jrc_hela-3\", label=\"ne_pred\"),\n",
    "                fluorophore=\"mTurquoise\",\n",
    "            ),\n",
    "            ms.FluorophoreDistribution(\n",
    "                distribution=ms.CosemLabel(dataset=\"jrc_hela-3\", label=\"er-mem_pred\"),\n",
    "                fluorophore=\"EYFP\",\n",
    "            ),\n",
    "            ms.FluorophoreDistribution(\n",
    "                distribution=ms.CosemLabel(dataset=\"jrc_hela-3\", label=\"mito-mem_pred\"),\n",
    "                fluorophore=\"mScarlet\",\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    channels=[create_custom_channel(min_wave=300, max_wave=800)],\n",
    "    modality=ms.Confocal(pinhole_au=2),\n",
    "    detector=ms.CameraCCD(qe=0.82, read_noise=6),\n",
    "    output_path=\"h2-cf.tif\",\n",
    "    settings=ms.Settings(max_psf_radius_aus=2),\n",
    "    emission_bins=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from microsim.schema.optical_config.lib import EYFP, FITC\n",
    "\n",
    "# sim = ms.Simulation(\n",
    "#     truth_space=ms.ShapeScaleSpace(shape=(64, 256, 256), scale=(0.04, 0.02, 0.02)),\n",
    "#     output_space={\"downscale\": 4},\n",
    "#     sample=ms.Sample(\n",
    "#         labels=[\n",
    "#             ms.FluorophoreDistribution(\n",
    "#                 distribution=ms.MatsLines(density=1, length=8, azimuth=1, max_r=math.sqrt(2)),\n",
    "#                 fluorophore=\"EGFP\",\n",
    "#             ),\n",
    "#             ms.FluorophoreDistribution(\n",
    "#                 distribution=ms.MatsLines(density=0.1, length=30, azimuth=50, max_r=math.sqrt(2)),\n",
    "#                 fluorophore=\"EYFP\",\n",
    "#             ),\n",
    "#         ]\n",
    "#     ),\n",
    "#     modality=ms.Confocal(pinhole_au=1),\n",
    "#     settings=ms.Settings(random_seed=100, max_psf_radius_aus=4),\n",
    "#     detector=ms.CameraCCD(qe=0.82, read_noise=4, bit_depth=12),\n",
    "#     # channels=[FITC, EYFP],\n",
    "#     channels=[create_custom_channel(min_wave=300, max_wave=800)],\n",
    "#     emission_bins=32,\n",
    "#     # binning_strategy=\"equal_space\"\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth stage is responsible for generating the positions of the fluorophores in the 3D space. Each [FluorophoreDistribution][microsim.schema.FluorophoreDistribution] object in the simulation specifies the position, number, species (e.g. mEGFP) of fluorophores in the volume. The ground truth will have dimensions (F, Z, Y, X) where len(F) is determined by the number of labels in the sample field of the Simulation; the values in the ground truth array represent the number of fluorophores present at each voxel in the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = sim.ground_truth()\n",
    "print(gt.shape, gt.coords) # (F, Z, Y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of fluorophores per pixel\n",
    "print(int(np.sum(gt[0, ...] == 0))) # What does it change to have more than 1 fluorophore per pixel? Twice the emission intensity there?\n",
    "print(int(np.sum(gt[0, ...] == 1)))\n",
    "print(int(np.sum(gt[0, ...] == 2)))\n",
    "print(int(np.sum(gt[0, ...] == 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the fluorophore distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make MIP over z-axis\n",
    "gt_mip = gt.max(dim='z')\n",
    "\n",
    "cmaps = [\"Blues\", \"Greens\", \"Reds\", \"Grays\"]\n",
    "_, ax = plt.subplots(1, gt_mip.shape[0], figsize=(10, 5))\n",
    "for i in range(gt_mip.shape[0]):\n",
    "    ax[i].imshow(gt_mip[i, ...], cmap=cmaps[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: how is the Flurophore distribution generated? -> Look into `ms.FluorophoreDistribution`!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the emission spectra (common approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_imgs = []\n",
    "channels = tuple(range(len(sim.channels)))\n",
    "for channel_idx in channels:\n",
    "    emission_imgs.append(sim.emission_flux(gt, channel_idx=channel_idx))\n",
    "    \n",
    "print(len(emission_imgs), emission_imgs[0].shape) # shape should be (W, C, F, Z, Y, X), with C=1 for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_imgs[0][\"w\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the emission spectra (new approach)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "1. Get the emission spectrum for each fluorophore.\n",
    "2. Get min and max wavelength over all the spectra.\n",
    "3. Create the same bins for all the spectra, using common min and max wavelength and number of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission_imgs = []\n",
    "# channels = tuple(range(len(sim.channels)))\n",
    "# for channel_idx in channels:\n",
    "#     emission_imgs.append(sim.spectral_emission_flux(gt, channel_idx=channel_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = sim.channels[0]\n",
    "em_img, em_spectra, em_binned_spectra = sim.spectral_emission_flux(gt, channel_idx=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print histograms of spectra and binned spectra for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_img.shape, em_spectra, em_binned_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for em_spectra\n",
    "em_binned_spectra[0][\"w_bins\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrum_plot(spectra):\n",
    "    num_fluorophores = len(spectra)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, num_fluorophores))\n",
    "    _, ax = plt.subplots(1, num_fluorophores, figsize=(10, 6*num_fluorophores))\n",
    "    for i in range(num_fluorophores):\n",
    "        ax[i].bar(\n",
    "            spectra[i].wavelength.magnitude, \n",
    "            spectra[i].intensity.magnitude,\n",
    "            width=1, \n",
    "            color=colors[i],\n",
    "            edgecolor='black', \n",
    "            alpha=0.7\n",
    "        )\n",
    "        ax[i].set_xlabel('Wavelength')\n",
    "        ax[i].set_ylabel('Intensity')\n",
    "        ax[i].set_title('Spectrum Bar Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_spectrum_plot(binned_spectra):\n",
    "    num_fluorophores = len(binned_spectra)\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, num_fluorophores))\n",
    "    _, ax = plt.subplots(1, num_fluorophores, figsize=(10, 6))\n",
    "    for i in range(num_fluorophores):\n",
    "        wave_intervals = binned_spectra[i][\"w_bins\"].values\n",
    "        bin_centers = [interval.mid for interval in wave_intervals]\n",
    "        bin_widths = [interval.length for interval in wave_intervals]\n",
    "        ax[i].bar(\n",
    "            bin_centers,\n",
    "            binned_spectra[i].values,\n",
    "            width=bin_widths, \n",
    "            color=colors[i],\n",
    "            edgecolor='black', \n",
    "            alpha=0.5\n",
    "        )\n",
    "        ax[i].set_xlabel('Wavelength')\n",
    "        ax[i].set_ylabel('Intensity')\n",
    "        ax[i].set_title('Spectrum Bar Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_plot(em_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_spectrum_plot(em_binned_spectra)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize hyperspectral images using `napari`\n",
    "\n",
    "We need the following visualizations:\n",
    "- Each fluorophore separately\n",
    "- Sum of fluorophores\n",
    "\n",
    "NOTE: since we have 3D images we used max intensity projections over z-axis.\n",
    "\n",
    "NOTE: the 3rd dimension will represent the different wavelength bands (i.e., dims are X, Y, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the single fluorophore image and the overlapped ones (squeeze channel dimension)\n",
    "fluor1_em_img = em_img[:, :, 0, ...].squeeze()\n",
    "fluor2_em_img = em_img[:, :, 1, ...].squeeze()\n",
    "fluor3_em_img = em_img[:, :, 2, ...].squeeze()\n",
    "print(fluor1_em_img.shape, fluor2_em_img.shape, fluor3_em_img.shape)\n",
    "\n",
    "mixed_em_img = np.sum(em_img, axis=2).squeeze()\n",
    "print(mixed_em_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MIP images\n",
    "from microsim.schema.dimensions import Axis\n",
    "\n",
    "fluor1_em_mip = fluor1_em_img.max(dim=Axis.Z)\n",
    "fluor2_em_mip = fluor2_em_img.max(dim=Axis.Z)\n",
    "fluor3_em_mip = fluor3_em_img.max(dim=Axis.Z)\n",
    "mixed_em_mip = mixed_em_img.max(dim=Axis.Z)\n",
    "\n",
    "print(fluor1_em_mip.shape, fluor2_em_mip.shape, fluor3_em_mip.shape, mixed_em_mip.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(fluor1_em_mip).values, np.min(fluor1_em_mip).values, fluor1_em_mip.mean().values)\n",
    "print(np.max(fluor2_em_mip).values, np.min(fluor2_em_mip).values, fluor2_em_mip.mean().values)\n",
    "print(np.max(mixed_em_mip).values, np.min(mixed_em_mip).values, mixed_em_mip.mean().values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: intensities should be normalized into a 16bit range before visualization, otherwise we get a saturated image.\n",
    "\n",
    "Why aren't the intensities not normalized despite the presence of the field validator for the intensity attribute in the pydantic model of the `Spectrum` class?\n",
    "\n",
    "I guess the normalization triggered by the validator only happens when the spectrum is first initialized. However, in the case of spectra associated to fluorophores, \n",
    "we have that after they are obtained from FPbase, they go through several manipulation steps which modify their magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_global(data):\n",
    "    min_val = data.min().item()\n",
    "    max_val = data.max().item()\n",
    "    normalized_data = ((data - min_val) / (max_val - min_val) * 65535).astype(np.uint16)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fluor1_em_img = normalize_global(fluor1_em_img)\n",
    "norm_fluor2_em_img = normalize_global(fluor2_em_img)\n",
    "norm_fluor3_em_img = normalize_global(fluor3_em_img)\n",
    "norm_mixed_em_img = normalize_global(mixed_em_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(norm_fluor1_em_img).values, np.min(norm_fluor1_em_img).values, norm_fluor1_em_img.values[norm_fluor1_em_img.values != 0.0].mean())\n",
    "print(np.max(norm_fluor2_em_img).values, np.min(norm_fluor2_em_img).values, norm_fluor2_em_img.values[norm_fluor2_em_img.values != 0.0].mean())\n",
    "print(np.max(norm_fluor3_em_img).values, np.min(norm_fluor3_em_img).values, norm_fluor3_em_img.values[norm_fluor3_em_img.values != 0.0].mean())\n",
    "print(np.max(norm_mixed_em_img).values, np.min(norm_mixed_em_img).values, norm_mixed_em_img.values[norm_mixed_em_img.values != 0.0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_fluor1_em_mip = normalize_global(fluor1_em_mip)\n",
    "norm_fluor2_em_mip = normalize_global(fluor2_em_mip)\n",
    "norm_fluor3_em_mip = normalize_global(fluor3_em_mip)\n",
    "norm_mixed_em_mip = normalize_global(mixed_em_mip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(norm_fluor1_em_mip).values, np.min(norm_fluor1_em_mip).values, norm_fluor1_em_mip.values[norm_fluor1_em_mip.values != 0.0].mean())\n",
    "print(np.max(norm_fluor2_em_mip).values, np.min(norm_fluor2_em_mip).values, norm_fluor2_em_mip.values[norm_fluor2_em_mip.values != 0.0].mean())\n",
    "print(np.max(norm_fluor3_em_mip).values, np.min(norm_fluor3_em_mip).values, norm_fluor3_em_mip.values[norm_fluor3_em_mip.values != 0.0].mean())\n",
    "print(np.max(norm_mixed_em_mip).values, np.min(norm_mixed_em_mip).values, norm_mixed_em_mip.values[norm_mixed_em_mip.values != 0.0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.all(norm_fluor1_em_img[2, ...] == norm_fluor1_em_img[5, ...] ).item())\n",
    "# print(np.sum(norm_fluor1_em_img[2, ...] == norm_fluor1_em_img[5, ...]) / sum(norm_fluor1_em_img[2, ...].shape[1:]))\n",
    "# print(np.sum(norm_fluor1_em_img[2, ...] - norm_fluor1_em_img[5, ...] ) / np.sum(norm_fluor1_em_img[2, ...]))\n",
    "\n",
    "_, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "ax[0,0].imshow(norm_fluor1_em_mip[1, ...], cmap=\"Grays\")\n",
    "ax[0,1].imshow(norm_fluor1_em_mip[5, ...], cmap=\"Greens\")\n",
    "ax[0,2].imshow(abs(norm_fluor1_em_mip[1, ...] - norm_fluor1_em_mip[5, ...]), cmap=\"Reds\")\n",
    "ax[1,0].imshow(norm_fluor2_em_mip[6, ...], cmap=\"Grays\")\n",
    "ax[1,1].imshow(norm_fluor2_em_mip[13, ...], cmap=\"Greens\")\n",
    "ax[1,2].imshow(abs(norm_fluor2_em_mip[6, ...] - norm_fluor2_em_mip[13, ...]), cmap=\"Reds\")\n",
    "ax[2,0].imshow(norm_fluor3_em_mip[10, ...], cmap=\"Grays\")\n",
    "ax[2,1].imshow(norm_fluor3_em_mip[14, ...], cmap=\"Greens\")\n",
    "ax[2,2].imshow(abs(norm_fluor3_em_mip[10, ...] - norm_fluor3_em_mip[14, ...]), cmap=\"Reds\")\n",
    "\n",
    "print(np.sum(abs(norm_fluor1_em_mip[1, ...] - norm_fluor1_em_mip[1, ...])) / np.sum(norm_fluor1_em_mip[2, ...]))\n",
    "print(np.sum(abs(norm_fluor2_em_mip[6, ...] - norm_fluor2_em_mip[13, ...])) / np.sum(norm_fluor2_em_mip[6, ...]))\n",
    "print(np.sum(abs(norm_fluor3_em_mip[10, ...] - norm_fluor3_em_mip[14, ...])) / np.sum(norm_fluor3_em_mip[10, ...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(norm_fluor1_em_mip, name=\"Fluorophore 1\", colormap=\"blue\", blending=\"additive\",  contrast_limits=(0, 65535))\n",
    "viewer.add_image(norm_fluor2_em_mip, name=\"Fluorophore 2\", colormap=\"yellow\", blending=\"additive\",  contrast_limits=(0, 65535))\n",
    "viewer.add_image(norm_fluor3_em_mip, name=\"Fluorophore 3\", colormap=\"red\", blending=\"additive\",  contrast_limits=(0, 65535))\n",
    "viewer.add_image(norm_mixed_em_mip, name=\"Mixed\", blending=\"additive\",  contrast_limits=(0, 65535))\n",
    "\n",
    "# viewer.add_image(norm_fluor1_em_img, name=\"Fluorophore 1\", colormap=\"blue\", blending=\"additive\")\n",
    "# viewer.add_image(norm_fluor2_em_img, name=\"Fluorophore 2\", colormap=\"yellow\", blending=\"additive\")\n",
    "# viewer.add_image(norm_fluor3_em_img, name=\"Fluorophore 3\", colormap=\"red\", blending=\"additive\")\n",
    "# viewer.add_image(norm_mixed_em_img, name=\"Mixed\", blending=\"additive\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Towards Hyperspectral images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: Given binned data in W bins, find a mapping between this and a smaller binning with W' bins "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emission spectrum has now shape `(W, C, F, Z, Y, X)`. We assume for simplicity to have a single frequency channels, namely `C=1`.\n",
    "\n",
    "Our aim here is double:\n",
    "1. First, for each fluorophore separately (i.e., along `Axis.F`), we want to re-bin the wavelengths in order to get `W'=32` bands. Therefore, this step provides the ground truth *unmixed* images.\n",
    "2. Then, we justappose (i.e., sum) along the fluorophore dimension to get the *mixed* spectral image.\n",
    "\n",
    "After this step we will have the *mixed* spectral image of shape `(W', C, Z, X, Y)`, and the *unmixed* ones (ground truth).\n",
    "\n",
    "NOTE: it is useful to have `W >> W'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = emission_imgs[0]\n",
    "img.shape, img.coords, type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = img[\"w\"].values\n",
    "# intervals, type(intervals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from microsim.schema.dimensions import Axis\n",
    "\n",
    "def reduce_bins(\n",
    "    da: xr.DataArray, \n",
    "    W_new: int = 32\n",
    ") -> xr.DataArray:\n",
    "    \n",
    "    W, C, F, Z, Y, X = da.shape\n",
    "    assert W_new < W, f\"The new number of bins W'={W_new} must be smaller than the original number of bins W={W}\"\n",
    "    \n",
    "    old_intervals = da[Axis.W].values\n",
    "    \n",
    "    # Initialize the new data array\n",
    "    new_data = np.zeros((W_new, C, F, Z, Y, X))\n",
    "\n",
    "    # Calculate the size of new bins and define new intervals\n",
    "    start, end = old_intervals[0].left, old_intervals[-1].right\n",
    "    bin_size = (end - start) // (W_new + 1)\n",
    "    # NOTE: new biins should be the result of merging old bind, since we want to keep the same delimiters\n",
    "    new_intervals = pd.IntervalIndex.from_breaks(\n",
    "        # np.linspace(start, end, W_new + 1),\n",
    "        np.arange(start, end, step=bin_size), \n",
    "        closed='right'\n",
    "    )\n",
    "    # Set the right value of the last interval to the end value of the spectrum\n",
    "    last_interval = pd.Interval(left=new_intervals[-1].left, right=end, closed=\"right\")\n",
    "    new_intervals = [interval for interval in new_intervals[:-1]] + [last_interval]\n",
    "\n",
    "    # Merge intervals\n",
    "    for i in range(W_new):\n",
    "        start = int(i * bin_size)\n",
    "        end = int((i + 1) * bin_size) if i != W_new - 1 else W\n",
    "        new_data[i] = da[start:end].sum(dim=Axis.W)\n",
    "\n",
    "    # Create new DataArray with the reduced bins\n",
    "    new_da = xr.DataArray(\n",
    "        new_data, \n",
    "        coords=[new_intervals, da.coords[Axis.C], da.coords[Axis.F], da.coords[Axis.Z], da.coords[Axis.Y], da.coords[Axis.X]],\n",
    "        dims=[Axis.W, Axis.C, Axis.F, Axis.Z, Axis.Y, Axis.X]\n",
    "    )\n",
    "\n",
    "    return new_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def rebin(original_bins, new_bin_count):\n",
    "    \n",
    "    original_bin_count = len(original_bins)\n",
    "    \n",
    "    if new_bin_count > original_bin_count:\n",
    "        raise ValueError(\"New bin count must be less than or equal to the original bin count.\")\n",
    "    \n",
    "    bins_per_new_bin = original_bin_count / new_bin_count\n",
    "    new_bins = []\n",
    "    \n",
    "    start_idx = 0\n",
    "    for i in range(new_bin_count):\n",
    "        end_idx = min(math.ceil((i + 1) * bins_per_new_bin), original_bin_count)\n",
    "        start_bin = original_bins[start_idx]\n",
    "        end_bin = original_bins[end_idx - 1]\n",
    "        new_bins.append(pd.Interval(left=start_bin.left, right=end_bin.right, closed='right'))\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    return pd.IntervalIndex(new_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "original_bins = pd.IntervalIndex.from_tuples([(0, 2), (2, 5), (5, 8)], closed='right')\n",
    "new_bin_count = 2\n",
    "new_bins = rebin(original_bins, new_bin_count)\n",
    "print(new_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_intervals = rebin(intervals[:10], 7)\n",
    "print(intervals[:10], len(intervals[:10]))\n",
    "print(new_intervals, len(new_intervals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small test to check the function\n",
    "# data = np.array(\n",
    "#     [[\n",
    "#         [[[[1, 1, 1], [1, 1, 1], [1, 1, 1]]], \n",
    "#         [[[1, 1, 1], [1, 1, 1], [1, 1, 1]]]]\n",
    "#     ], \n",
    "#     [\n",
    "#         [[[[1, 1, 1], [1, 1, 1], [1, 1, 1]]], \n",
    "#         [[[1, 1, 1], [1, 1, 1], [1, 1, 1]]]]\n",
    "#     ], \n",
    "#     [\n",
    "#         [[[[1, 1, 1], [1, 1, 1], [1, 1, 1]]], \n",
    "#         [[[1, 1, 1], [1, 1, 1], [1, 1, 1]]]]\n",
    "#     ]]\n",
    "# )\n",
    "# OR\n",
    "W, C, F, Z, Y, X = 9, 1, 2, 1, 3, 3  # Original dimensions\n",
    "data = np.ones((W, C, F, Z, Y, X))\n",
    "print(data.shape)\n",
    "\n",
    "# Define bins as pandas interval objects\n",
    "intervals = pd.IntervalIndex.from_breaks(range(W + 1), closed='right')\n",
    "print(intervals)\n",
    "\n",
    "# Create the xarray.DataArray\n",
    "da = xr.DataArray(\n",
    "    data, \n",
    "    coords=[intervals, range(C), range(F), range(Z), range(Y), range(X)], \n",
    "    dims=[Axis.W, Axis.C, Axis.F, Axis.Z, Axis.Y, Axis.X]\n",
    ")\n",
    "\n",
    "# Reduce the bins to W' where W' < W\n",
    "W_new = 2  # Example: reduce to 4 bins\n",
    "new_da = reduce_bins(da, W_new)\n",
    "\n",
    "# Print shapes\n",
    "print(\"Original shape:\", da.shape)\n",
    "print(\"New shape:\", new_da.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the real data\n",
    "# sliced_img = img[:5, ...]\n",
    "# sliced_img_reduced = reduce_bins(sliced_img, W_new=3)\n",
    "img_reduced = reduce_bins(img, W_new=32)\n",
    "img_reduced.shape, img_reduced.coords[Axis.W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[5, :, 0, ...].sum().values)\n",
    "print(img[5, :, 1, ...].sum().values)\n",
    "print(img[6, :, 0, ...].sum().values)\n",
    "print(img[6, :, 1, ...].sum().values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: In `Simulation.emission_flux()` replace the `\"equal_area\"` binning with equispaced bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Bin(NamedTuple):\n",
    "    # TODO : include units for each of these. Use pint.\n",
    "    \"\"\"One interval.\"\"\"\n",
    "\n",
    "    start: float\n",
    "    end: float\n",
    "    mean: float | None = None\n",
    "    mode: float | None = None\n",
    "\n",
    "    def __contains__(self, x: object) -> bool:\n",
    "        try:\n",
    "            return self.start <= x <= self.end  # type: ignore\n",
    "        except TypeError:\n",
    "            return False\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        if self.start is not None:\n",
    "            assert self.end is not None\n",
    "            return f\"[{self.start:.2f}-{self.end:.2f}]\"\n",
    "        elif self.mean is not None:\n",
    "            return f\"Mean:{self.mean:.2f}\"\n",
    "        else:\n",
    "            assert self.mode is not None\n",
    "            return f\"Mode:{self.mode:.2f}\"\n",
    "\n",
    "\n",
    "def _generate_bins_equal_space(\n",
    "    x: np.ndarray, \n",
    "    num_bins: int\n",
    ") -> list[tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Split the range of values in x into num_bins equally spaced bins.\n",
    "    If len(x) is not divisible by num_bins, the last bin will have more elements.\n",
    "    \"\"\"\n",
    "    bins = []\n",
    "    start = 0\n",
    "    bin_size = len(x) // num_bins\n",
    "    for i in range(num_bins):\n",
    "        end = start + bin_size\n",
    "        bins.append(Bin(start=x[start], end=x[end]))\n",
    "        start = end\n",
    "        \n",
    "    if bins[-1].end != x[-1]:\n",
    "        bins[-1] = Bin(start=bins[-1].start, end=x[-1])\n",
    "        \n",
    "    return bins\n",
    "\n",
    "arr = np.arange(463.0, 701., 1)\n",
    "bins = _generate_bins_equal_space(arr, 32)\n",
    "bins, len(bins) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
